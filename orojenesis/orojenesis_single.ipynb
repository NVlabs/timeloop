{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28516bf",
   "metadata": {},
   "source": [
    "# Orojenesis Artifact - Single-Ensum\n",
    "\n",
    "The ipython notebook file contains calls to Orojenesis to reproduce results in the ISCA'24 *\"Mind the Gap: Attainable Data Movement and Operational Intensity Bounds for Tensor Algorithms\"* paper. \n",
    "\n",
    "## 0.  Setup Software Dependencies \n",
    " Please first run install.sh to install software dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if \"TIMELOOP_BASE_PATH\" not in os.environ:\n",
    "    timeloop_path = input(\"Please specify the path to Timeloop repo (default: \" +  os.getcwd() + \"/timeloop):\" ) or os.getcwd() + \"/timeloop\"\n",
    "    os.environ[\"TIMELOOP_BASE_PATH\"] = timeloop_path\n",
    "os.environ[\"TIMELOOP_ENABLE_FIRST_READ_ELISION\"] = \"1\"\n",
    "print(\"Path to timeloop repo: \", os.environ[\"TIMELOOP_BASE_PATH\"])\n",
    "import src.utils as utils\n",
    "import src.plots as plots\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9c334",
   "metadata": {},
   "source": [
    "## 1. Generate Single-Einsum Bounds\n",
    "The *Orojenesis* flow has been integrated into Timeloop mapper to log the statistics of all pareto-optimal mappings. In order to turn the *orojenesis* option on, set `log-oaves` to `True` in the Timeloop mapper configuration file, e.g., `./configs/single-einsum/conv_mapper.yaml`. The flow generates the `timeloop-mapper.oaves.csv` file under the output directory and we need to run a post processing script `./src/oaves_process_data.py` to merge the pareto-optimal mappings from different mapper threads. \n",
    "\n",
    "We first specify the output directory for the results, path to the speeder architecture, and the mapper constraints for convolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = pathlib.Path('./outputs/single-einsum')\n",
    "arch_yaml = pathlib.Path('./configs/single-einsum/arch.yaml')\n",
    "mapper_yaml = pathlib.Path('./configs/single-einsum/conv_mapper.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151db91",
   "metadata": {},
   "source": [
    "### Run Orojenesis search to generate bounds  (Estimated Runtime: 8 hours) \n",
    "This artifact  takes **several hour** to finish. The actual runtime may vary depending on your processor's speed and core count. Once the bounds are generated, the following code can directly load the generated data without initiating a rerun.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_rerun = False\n",
    "# Fig.1 Motivation figure \n",
    "fig1_prob = utils.Conv(P=16384, C=1024, K=1024)\n",
    "utils.GenerateBound(fig1_prob, output_dir, arch_yaml, mapper_yaml, force_rerun=force_rerun)\n",
    "\n",
    "# Fig.10 Impact of GEMM sizes. \n",
    "fig10_probs = []\n",
    "prob=[2048,2048,2048]\n",
    "for i in range(-1, 6):\n",
    "    if i >= 0:\n",
    "        idx = 2 - (i % 3)\n",
    "        prob[idx] *= 2\n",
    "    fig10_prob = utils.Conv(P=prob[0], C=prob[1], K=prob[2])\n",
    "    utils.GenerateBound(fig10_prob, output_dir, arch_yaml, mapper_yaml, keep_one_best_entry_across_buf=True, force_rerun=force_rerun)\n",
    "    fig10_probs.append(fig10_prob)\n",
    "\n",
    "# Fig.11 Maximal effectualbuffer ratio over total operand size. \n",
    "fig11_probs = []\n",
    "factors = [0.5, 1, 2]\n",
    "for m in factors:\n",
    "    for k in factors:\n",
    "        for n in factors: \n",
    "            prob = [int(4096 * m), int(4096 * k), int(4096 * n)]\n",
    "            fig11_prob = utils.Conv(P=prob[0], C=prob[1], K=prob[2])\n",
    "            utils.GenerateBound(fig11_prob, output_dir, arch_yaml, mapper_yaml, keep_one_best_entry_across_buf=True, force_rerun=force_rerun)\n",
    "            fig11_probs.append(fig11_prob)\n",
    "\n",
    "# Fig.12 Impact of conv configs. \n",
    "fig12_probs = []\n",
    "probs = ['1_1_16_16_64_64_1_1_1_1_1', '3_3_16_16_64_64_1_1_1_1_1', '5_5_16_16_64_64_1_1_1_1_1', '3_3_16_16_64_64_1_2_2_1_1', '3_3_16_16_64_64_1_1_1_2_2']\n",
    "for prob in probs:\n",
    "    factors = [int(string) for string in prob.split('_')]\n",
    "    fig12_prob = utils.Conv(*factors)\n",
    "    utils.GenerateBound(fig12_prob, output_dir, arch_yaml, mapper_yaml, \\\n",
    "                        keep_one_best_entry_across_buf=True, force_rerun=force_rerun)\n",
    "    fig12_probs.append(fig12_prob)\n",
    "\n",
    "# Fig.13 Impact of BMM heads with fixed total OPs. bmm_QK[hlf,hfl->hll]\n",
    "# This experiment takes roughly 5 mins to finish.\n",
    "fig13_probs = []\n",
    "for i in range(8):\n",
    "    num_heads = int(2**i)\n",
    "    K = 4096 // num_heads\n",
    "    fig13_prob = utils.GBMM(M=4096, K=K, N=4096, H=num_heads)\n",
    "    utils.GenerateBound(fig13_prob, output_dir, arch_yaml, pathlib.Path('./configs/single-einsum/gbmm_mapper.yaml'), \\\n",
    "                        keep_one_best_entry_across_buf=True, force_rerun=force_rerun)\n",
    "    fig13_probs.append(fig13_prob)\n",
    "\n",
    "# Fig.14 Impact of BMM groups. Note that postprocessing is required to obtain the total OPs in Timeloop\n",
    "# This experiment takes roughly 6.5 hours to finish.\n",
    "fig14_probs = []\n",
    "for i in range(6):\n",
    "    num_groups = int(2**i)\n",
    "    fig14_prob = utils.GBMM(M=4096, K=128, N=4096, H=32, G=num_groups)\n",
    "    utils.GenerateBound(fig14_prob, output_dir, arch_yaml, pathlib.Path('./configs/single-einsum/gbmm_mapper.yaml'), \\\n",
    "                        keep_one_best_entry_across_buf=True, force_rerun=force_rerun)\n",
    "    fig14_probs.append(fig14_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f04e4",
   "metadata": {},
   "source": [
    "## 2. Plot Single-Einsum Bounds\n",
    "We save the generated figures under `fig_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = pathlib.Path('./figs')\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93ebca",
   "metadata": {},
   "source": [
    "## Fig.1: Backing-store accesses bound for 16384x1024x1024 GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_files = utils.get_stats_files(output_dir, [fig1_prob])\n",
    "dfs = utils.get_dfs(stats_files, get_opt=True)\n",
    "y_end_value=10**8\n",
    "plots.plot_dfs(dfs, logy=True, logx=True, shape_name=\"fig1\", probs=[fig1_prob], motivation=True, plot_min=True, plot_buf=False, plot_all_mappings=True, xlim=(0.5, y_end_value), ylim=(None, 10**10), y_end_value=10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27648672",
   "metadata": {},
   "source": [
    "## Fig.10: Backing-store accesses and OI bounds for various GEMM shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "legends = ['2048_2048_2048','2048_2048_4096', '2048_4096_4096', '4096_4096_4096', '4096_4096_8192', '4096_8192_8192', '8192_8192_8192']\n",
    "stats_files = utils.get_stats_files(output_dir, fig10_probs)    \n",
    "dfs = utils.get_dfs(stats_files, get_opt=True)\n",
    "ax = plots.plot_dfs(dfs, legends=legends, dpi=300, logy=True, logx=True, shape_name=\"fig10\", figsize=(2.5, 2.5),  xlim=(10**4, 1*10**8), ylim=(0, 10*10**9), y_end_value=2*10**8, legend_fontsize=7.5)\n",
    "\n",
    "plots.plot_dfs(dfs, legends=legends, dpi=300, logy=False, logx=False, metric=\"Op_Intensity\", shape_name=\"fig10\",  figsize=(2.5,2.5),  xlim=(10**4, 2*10**8), ylim=(0, 6*10**3), y_end_value=2*10**8, legend_fontsize=7.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092c7b1",
   "metadata": {},
   "source": [
    "## Fig.11: Maximal effectual buffer ratio over total operand size for various GEMMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e144f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "legends = []\n",
    "factors = [0.5, 1, 2]\n",
    "for m in factors:\n",
    "    for k in factors:\n",
    "        for n in factors: \n",
    "            M = int(4096 * m)\n",
    "            N = int(4096 * k)\n",
    "            K = int(4096 * n)\n",
    "            legends.append(f'{M}_{K}_{N}')    \n",
    "plots.plot_bar_ratios(output_dir, fig11_probs, legends, fig_name='fig11', figsize=(6, 6), sort_ratio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49ecd1a",
   "metadata": {},
   "source": [
    "## Fig.12: Backing-store accesses and OI bounds for various convolution configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf5e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legends = ['1x1 conv', '3x3 conv', '5x5 conv', '3x3 conv\\nstride 2', '3x3 conv\\ndilation 2']\n",
    "stats_files = utils.get_stats_files(output_dir, fig12_probs)    \n",
    "dfs = utils.get_dfs(stats_files, get_opt=True)\n",
    "y_end_value = 1*10**5\n",
    "plots.plot_dfs(dfs, legends=legends, dpi=300, logy=False, logx=True, shape_name=\"fig12\", figsize=(2.5,2.5),  xlim=(None,y_end_value), ylim=(0, 4*10**7), y_end_value=y_end_value, legend_fontsize=9)\n",
    "plots.plot_dfs(dfs, legends=legends, dpi=300, logy=False, logx=True, metric=\"Op_Intensity\", shape_name=\"fig12\",  figsize=(2.5,2.5),  xlim=(None,y_end_value), ylim=(0, 400), y_end_value=y_end_value, legend_fontsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366475b",
   "metadata": {},
   "source": [
    "## Fig.13: Backing-store accesses and OI bounds for BMMs with different number of heads but identical OPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d26ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "legends = []\n",
    "for i in range(8):\n",
    "    num_heads = int(2**i)\n",
    "    K = 4096 // num_heads\n",
    "    K_value = f'{K//1000}k' if K > 1000 else K\n",
    "    legends.append(f'H={num_heads}, K={K_value}')\n",
    "\n",
    "stats_files = utils.get_stats_files(output_dir, fig13_probs)        \n",
    "dfs = utils.get_dfs(stats_files, get_opt=True)\n",
    "y_end_value = 2*10**8\n",
    "plots.plot_dfs(dfs, legends=legends, dpi=300, logy=False, logx=True, shape_name=\"fig13\", figsize=(2.5,2.5),  xlim=(10**3,y_end_value), ylim=(0, 4*10**9), y_end_value=y_end_value, legend_fontsize=8)\n",
    "plots.plot_dfs(dfs, legends=legends, dpi=300, logy=False, logx=True, metric=\"Op_Intensity\", shape_name=\"fig13\",  figsize=(2.5,2.5),  xlim=(10**3,y_end_value), ylim=(0, 3*10**3), y_end_value=y_end_value, legend_fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b6d45",
   "metadata": {},
   "source": [
    "## Fig.14: Backing-store accesses and OI bounds for Grouped BMMs with different number of groups but identical OPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49500102",
   "metadata": {},
   "outputs": [],
   "source": [
    "legends = []\n",
    "for i in range(6):\n",
    "    num_groups = int(2**i) \n",
    "    if num_groups == 1:\n",
    "        legends.append(f'{num_groups} group')\n",
    "    else:\n",
    "        legends.append(f'{num_groups} groups')\n",
    "    \n",
    "    \n",
    "stats_files = utils.get_stats_files(output_dir, fig14_probs)        \n",
    "dfs = utils.get_dfs(stats_files, get_opt=True)\n",
    "total_compute = fig14_probs[0].get_compute_size()\n",
    "for i, df in enumerate(dfs):\n",
    "    dfs[i]['Op_Intensity'] = total_compute/dfs[i]['DRAM_Accesses']\n",
    "y_end_value = 2*10**8\n",
    "plots.plot_dfs(dfs, legends=legends, dpi=300, logy=False, logx=True, shape_name=\"QK_sweep_groups\", figsize=(2.5,2.5),  xlim=(None,y_end_value), ylim=(0, 1.5*10**12), y_end_value=y_end_value, legend_fontsize=8)\n",
    "plots.plot_dfs(dfs, legends=legends, dpi=300, logy=False, logx=True, metric=\"Op_Intensity\", shape_name=\"QK_sweep_groups\",  figsize=(2.5,2.5),  xlim=(None,y_end_value), ylim=(1, 140), y_end_value=y_end_value,  legend_fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6414f9a3",
   "metadata": {},
   "source": [
    "## 3. Validation on GPUs and Simba \n",
    "We validate the Orojenesis curve for a 4kx4kx4k GEMM on four NVIDIA GPUs and on a model of the Simba accelerator. \n",
    "\n",
    "## Fig.24a: Measured DRAM accesses on GPUs with different L2 sizes vs. Orojenesis Bounds\n",
    "This figure shows the DRAM accesses measured on NVIDIA GA100 GPUs with various L2 sizes  \n",
    "\n",
    "[OPTIONAL] Below is the instruction for getting the GPU dram access count using CULTASS.   \n",
    "1. Download and install the [CUTLASS library](https://github.com/NVIDIA/cutlass/tree/cutlass-3.5.0) following the [Quick Start Guide](https://github.com/NVIDIA/cutlass/blob/cutlass-3.5.0/media/docs/quickstart.md). Set the CUTLASS_NVCC_ARCH=80 to compile the library for A100 GPUs.  \n",
    "2. Download and install the GPU profiling tool Nsight Compute following the instructions (here)[https://developer.nvidia.com/tools-overview/nsight-compute/get-started].\n",
    "3. Navigate to the build directory of cutlass.  \n",
    "```\n",
    "cd <path-to-cutlass>/build\n",
    "```\n",
    "4. Run the following command to gather the DRAM accesses count for running fp32 4kx4kx4k on SMs.  \n",
    "```\n",
    "ncu  --cache-control all  --metrics dram__bytes_read.sum,dram__bytes_write.sum ./tools/profiler/cutlass_profiler --kernels=sgemm --gemm_kind=universal --m=4096 --n=4096 --k=4096 --A=f32:column --B=f32:column --C=f32:column --D=f32:column --verification-enabled=0   --profiling-enabled=1   --profiling-iterations=1 --warmup-iterations=0\n",
    "```\n",
    "5. Run the following command to gather the DRAM accesses count for running fp32 4kx4kx4k on tensor cores.  \n",
    "\n",
    "```\n",
    "ncu  --cache-control all  --metrics dram__bytes_read.sum,dram__bytes_write.sum \\\n",
    "./tools/profiler/cutlass_profiler \\\n",
    "    --kernels=cutlass_tensorop_s1688bf16gemm_256x128_16x3_nn_align4 \\\n",
    "    --operation=gemm \\\n",
    "    --op_class=tensorop \\\n",
    "    --gemm_kind=universal \\\n",
    "    --m=4096 --n=4096 --k=4096 \\\n",
    "    --A=f32:column --B=f32:column --C=f32:column --D=f32:column --accum=f32 \\\n",
    "    --verification-enabled=0   --profiling-enabled=1   --profiling-iterations=1 --warmup-iterations=0 \\\n",
    "    --mode=trace\n",
    "```\n",
    "\n",
    "6. Repeat the process on different GPUs. \n",
    "\n",
    "In this notebook, we provide the pregenerated GPU accesses to compare to the *Orojenesis* bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06396947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob = utils.Conv(P=4096, C=4096, K=4096)\n",
    "utils.GenerateBound(prob, output_dir, arch_yaml, mapper_yaml, \\\n",
    "                    keep_one_best_entry_across_buf=True, force_rerun=False)\n",
    "stats_files = utils.get_stats_files(output_dir, [prob])    \n",
    "dfs = utils.get_dfs(stats_files, get_opt=True)\n",
    "y_end_value = 2*10**8\n",
    "gpu_data = {\n",
    "    'simt': [[2*2**20, 24*2**20, 40*2**20, 50*2**20], [2.69*2**30, 650*2**20, 533*2**20, 373.39*2**20]],\n",
    "    'tensor': [[2*2**20, 24*2**20, 40*2**20, 50*2**20], [1.58*2**30, 561.51*2**20, 411.06*2**20,373.33*2**20]],\n",
    "}\n",
    "# df = dfs[0]\n",
    "# df.index=df.index*4\n",
    "# df['DRAM_Accesses'] = df['DRAM_Accesses']*4\n",
    "# print(df)\n",
    "ax = plots.plot_dfs(dfs, legends=['4k_4k_4k'], dpi=300, logy=False, logx=True, shape_name=\"MM_same_flops\", figsize=(2.5,2.5),  xlim=(10**6,y_end_value), ylim=(0, 4*10**9), y_end_value=y_end_value, plot_gpu_data=True, gpu_data=gpu_data, coefficient=4, legend_fontsize=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b8637",
   "metadata": {},
   "source": [
    "## Fig.24b: Measured DRAM accesses on Simba accelerator vs. Orojenesis Bounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ec458",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_output_dir = pathlib.Path('./outputs/validation')\n",
    "simba_arch_yaml = pathlib.Path('./configs/simba/simba-chip.yaml')\n",
    "simba_mapper_yaml = pathlib.Path('./configs/simba/mapper.yaml')\n",
    "\n",
    "prob = utils.Conv(P=4096, C=4096, K=4096)\n",
    "\n",
    "# It takes roughly 3 minute to generate 2000 valid mappings for each simba config. \n",
    "buf_KBs = [0.125, 1, 8, 64, 512]\n",
    "simba_csvs = []\n",
    "force_rerun = False\n",
    "for buf_KB in buf_KBs:\n",
    "    arch = utils.parse_yaml(simba_arch_yaml)\n",
    "    for idx, mem in enumerate(arch['arch']['storage']):\n",
    "        if mem['name'] == 'GlobalBuffer':\n",
    "            if buf_KB < 1:\n",
    "                del mem['sizeKB']\n",
    "                mem['entries'] = int(1024 * buf_KB)\n",
    "            else:\n",
    "                mem['sizeKB'] = buf_KB\n",
    "\n",
    "    output_subdir = val_output_dir / 'simba' / pathlib.Path(f'output_{buf_KB}')\n",
    "    output_subdir.mkdir(exist_ok=True, parents=True)\n",
    "    new_arch_yaml =  output_subdir / 'arch.yaml'\n",
    "    utils.store_yaml(new_arch_yaml, arch)\n",
    "    utils.GenerateBound(prob, output_subdir, new_arch_yaml, simba_mapper_yaml, keep_one_best_entry_across_buf=False, force_rerun=force_rerun)\n",
    "    stats_file = utils.get_stats_files(output_subdir, [prob], pareto_optimal=False)[0] \n",
    "    simba_csvs.append(stats_file)\n",
    "\n",
    "y_end_value = 2*10**8\n",
    "simba_dfs = utils.get_dfs(simba_csvs, scales=None, get_opt=False, get_mapping=False)\n",
    "stats_files = utils.get_stats_files(output_dir, [prob])    \n",
    "dfs = utils.get_dfs(stats_files, get_opt=True)\n",
    "ax = plots.plot_dfs(dfs, legends=['4k_4k_4k'], dpi=300, logy=False, logx=True, shape_name=\"simba_val\", figsize=(2.5,2.5),  xlim=(0,12**9), ylim=(0, 100*10**9), y_end_value=y_end_value, simba_dfs=simba_dfs, legend_fontsize=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
